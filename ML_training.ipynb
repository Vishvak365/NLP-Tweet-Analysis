{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('amazon_review_data.pd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert rating from double to int\n",
    "df['rating'] = df['rating'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1055634    5\n",
       "1137634    5\n",
       "284960     5\n",
       "1193986    4\n",
       "115403     5\n",
       "          ..\n",
       "531943     5\n",
       "1021656    4\n",
       "388207     4\n",
       "1035452    4\n",
       "518937     1\n",
       "Name: rating, Length: 1228064, dtype: int32"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_1_df = df.loc[df['rating'] == 1]\n",
    "rating_2_df = df.loc[df['rating'] == 2]\n",
    "rating_3_df = df.loc[df['rating'] == 3]\n",
    "rating_4_df = df.loc[df['rating'] == 4]\n",
    "rating_5_df = df.loc[df['rating'] == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_negative_df = rating_3_df\n",
    "rating_negative_df = rating_negative_df.append(rating_2_df)\n",
    "rating_negative_df = rating_negative_df.append(rating_1_df)\n",
    "\n",
    "rating_positive_df = rating_5_df\n",
    "rating_positive_df = rating_positive_df.append(rating_4_df)\n",
    "\n",
    "rating_negative_df['rating'] = 0\n",
    "rating_positive_df['rating'] = 1"
   ]
  },
  {
   "source": [
    "### Run one of the following cells"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numValues = 55000\n",
    "# df.drop(df.index, inplace=True)\n",
    "# df = df.append(rating_1_df[:numValues])\n",
    "# df = df.append(rating_2_df[:numValues])\n",
    "# df = df.append(rating_3_df[:numValues])\n",
    "# df = df.append(rating_4_df[:numValues])\n",
    "# df = df.append(rating_5_df[:numValues])\n",
    "# df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "numValues = min(len(rating_positive_df),len(rating_negative_df))\n",
    "df.drop(df.index, inplace=True)\n",
    "df = df.append(rating_positive_df[:numValues])\n",
    "df = df.append(rating_negative_df[:numValues])\n",
    "df = df.sample(frac=1)"
   ]
  },
  {
   "source": [
    "### Data splitting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset_split = 50000\n",
    "# max_features = 10000\n",
    "# train_X,test_X,train_y,test_y = train_test_split(df['reviews'][:subset_split], df['rating'][:subset_split], test_size=0.20, random_state=42)\n",
    "# train_len,test_len = len(train_X),len(test_X)\n",
    "# vectorizer = TfidfVectorizer(stop_words='english', max_features=max_features,strip_accents='unicode', norm='l2')\n",
    "# train_X = vectorizer.fit_transform(train_X).todense()\n",
    "# test_X = vectorizer.transform(test_X).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import bz2\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "source": [
    "### USING https://www.tensorflow.org/tutorials/text/text_classification_rnn"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "478382"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_split = 450_000\r\n",
    "train_X,test_X,train_y,test_y = train_test_split(df['reviews'][:subset_split], df['rating'][:subset_split], test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE=5_000\n",
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(np.array(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltsm_model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "ltsm_model.compile(loss=tf.keras.losses.mse,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "3000/3000 [==============================] - 368s 120ms/step - loss: 0.1578 - accuracy: 0.7719 - val_loss: 0.1122 - val_accuracy: 0.8443\n",
      "Epoch 2/3\n",
      "3000/3000 [==============================] - 428s 143ms/step - loss: 0.0984 - accuracy: 0.8680 - val_loss: 0.1103 - val_accuracy: 0.8539\n",
      "Epoch 3/3\n",
      "3000/3000 [==============================] - 384s 128ms/step - loss: 0.0771 - accuracy: 0.8989 - val_loss: 0.1021 - val_accuracy: 0.8615\n"
     ]
    }
   ],
   "source": [
    "with tf.device('GPU:0'):\n",
    "    ltsm_model.fit(train_X, train_y, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, dense_layer_call_fn, dense_1_layer_call_fn, embedding_layer_call_fn, dense_layer_call_fn while saving (showing 5 of 16). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: ltsm_model_86.tf\\assets\n",
      "INFO:tensorflow:Assets written to: ltsm_model_86.tf\\assets\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "ltsm_model.save('ltsm_model_5_epoch_better.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ltsm_model.predict(test_X)\n",
    "pred_0_1 = []\n",
    "for y in pred:\n",
    "    if y > .5:\n",
    "        pred_0_1.append(1)\n",
    "    else:\n",
    "        pred_0_1.append(0)\n",
    "accuracy_score(test_y[:s_ubset],pred_0_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(history.model.predict([\"yeah\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "# reconstructed_model = keras.models.load_model(\"ltsm_model_86.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.8549012]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "# reconstructed_model.predict([\"I love Apple and Android\"])"
   ]
  },
  {
   "source": [
    "### Using Tutorial https://www.kaggle.com/kevinautin/fully-convolutional-accuracy-94-4-15-min"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_features = 8192\n",
    "# maxlen = 128\n",
    "embed_size = 64\n",
    "# subset_split = 125000\n",
    "# train_X,test_X,train_y,test_y = train_test_split(df['reviews'][:subset_split], df['rating'][:subset_split], test_size=0.20)\n",
    "# tokenizer = Tokenizer(num_words=max_features)\n",
    "\n",
    "# token_train = tokenizer.texts_to_sequences(train_X)\n",
    "# token_test = tokenizer.texts_to_sequences(test_X)\n",
    "\n",
    "# train_X = pad_sequences(token_train, maxlen=maxlen, padding='post')\n",
    "# test_X = pad_sequences(token_test, maxlen=maxlen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input = Input(shape=(max_features,))\n",
    "# net = Embedding(max_features, embed_size)(input)\n",
    "# net = Dropout(0.2)(net)\n",
    "# net = BatchNormalization()(net)\n",
    "\n",
    "# net = Conv1D(32, 7, padding='same', activation='relu')(net)\n",
    "# net = BatchNormalization()(net)\n",
    "# net = Conv1D(32, 3, padding='same', activation='relu')(net)\n",
    "# net = BatchNormalization()(net)\n",
    "# net = Conv1D(32, 3, padding='same', activation='relu')(net)\n",
    "# net = BatchNormalization()(net)\n",
    "# net = Conv1D(32, 3, padding='same', activation='relu')(net)\n",
    "# net1 = BatchNormalization()(net)\n",
    "\n",
    "# net = Conv1D(1, 10000)(net)\n",
    "# net = GlobalAveragePooling1D()(net)\n",
    "# output = Activation('relu')(net)\n",
    "# model = Model(inputs = input, outputs = output)\n",
    "# model.compile(optimizer='adam', loss='mse', metrics=['acc'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('GPU:0'):\n",
    "#     model.fit(train_X, train_y, batch_size=64, epochs=5, validation_split=0.1)"
   ]
  },
  {
   "source": [
    "### Deep Learning Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# import keras\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers.core import Dense, Dropout, Activation\n",
    "# from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
    "# from keras.optimizers import Adadelta,Adam,RMSprop\n",
    "# from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.Sequential()\n",
    "# model.add(Dense(1024,activation=\"relu\", input_dim=25000))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(512, activation=\"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(64, activation=\"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(32, activation=\"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(1,activation='relu'))\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='mse',\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model.fit(train_X[:15000],Y_train[:15000], batch_size=64, epochs=10,verbose=1)\n",
    "# with tf.device('GPU:0'):\n",
    "#     model.fit(train_X,train_y, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # accuracy_score(test_y[:1000],model.predict(test_X[:1000]))\n",
    "# # s_ubset = 1000\n",
    "# s_ubset = len(test_y)\n",
    "# print(s_ubset)\n",
    "# pred = model.predict(test_X[:s_ubset])\n",
    "# # pred_t = model.predict(train_X[:100])\n",
    "# test_y = test_y.reset_index(drop=True)\n",
    "# # train_y = train_y.reset_index(drop=True)\n",
    "\n",
    "# pred_0_1 = []\n",
    "# for y in pred:\n",
    "#     if y > .5:\n",
    "#         pred_0_1.append(1)\n",
    "#     else:\n",
    "#         pred_0_1.append(0)\n",
    "# accuracy_score(test_y[:s_ubset],pred_0_1)\n",
    "\n",
    "# # pred = [for y in pred]\n",
    "# # for i in range(99):\n",
    "# #     print(pred[i][0],test_y[i])\n",
    "# # for i in range(99):\n",
    "# #     print(pred_t[i][0],train_y[i])"
   ]
  },
  {
   "source": [
    "### SVM classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # clf = MultinomialNB().fit(train_X, train_y[:100000])\n",
    "# subset_data = 1000\n",
    "# from sklearn import svm\n",
    "# clf = svm.SVC()\n",
    "# clf.fit(train_X[:subset_data], train_y[:subset_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titles_options = [(\"Confusion matrix, without normalization\", None),\n",
    "#                   (\"Normalized confusion matrix\", 'true')]\n",
    "# for title, normalize in titles_options:\n",
    "#     disp = plot_confusion_matrix(clf, test_X[:1000], test_y[:1000],\n",
    "#                                  display_labels=np.arange(1,3),\n",
    "#                                  cmap=plt.cm.Blues,\n",
    "#                                  normalize=normalize)\n",
    "#     disp.ax_.set_title(title)\n",
    "\n",
    "#     print(title)\n",
    "#     print(disp.confusion_matrix)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = [\"This is a product that is okay\"]\n",
    "# # # vectorizer = TfidfVectorizer()\n",
    "# # # train_X = vectorizer.fit_transform(train_X[:10000])\n",
    "# ya_yeet = vectorizer.transform(text).todense()\n",
    "# # clf.predict(ya_yeet)\n",
    "# model.predict(ya_yeet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}